{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoSpred\n",
    "\n",
    "Complete MSMS spectrum prediction workflow.\n",
    "\n",
    "This provides a workflow to prepare your own training datasets from raw files and convert them into tensors. These tensors are input for machine learning architectures. The architecture can be built using TensorFlow or PyTorch frameworks.\n",
    "\n",
    "Here we are predicting full MSMS spectrum as a set of (Mi, Ii) where Mi is the mass of the peak and Ii is the intensity of the peak. For the BiGRU model, the MSMS spectrum is presented as b/y ion series described in the original Prosit paper.\n",
    "\n",
    "Two machine learning architectures were demonstrated:\n",
    "- **Transformer**: Predicts full MSMS spectrum using transformer architecture\n",
    "- **BiGRU**: Predicts y-, b- ion intensities using BiGRU architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing Results with Docker\n",
    "\n",
    "To best test and experience usage of the software, we recommend using a Docker environment at the beginning. All the software dependencies were pre-installed in the **Docker image**, while model weights and example data were provided in the **capsule** folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prerequisites\n",
    "- [Docker Community Edition (CE)](https://www.docker.com/community-edition)\n",
    "- [nvidia-container-runtime](https://docs.docker.com/config/containers/resource_constraints/#gpu) for code that leverages the GPU\n",
    "- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) to use GPU in Docker containers\n",
    "- [GLIBCXX] Updated GCC compiler, version >= 3.4.29\n",
    "- Optional: Conda/Mamba installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup the Computing Environment\n",
    "\n",
    "Git clone the repo, download the pre-trained model `pretrained_models.zip` and `example.zip` from [FigShare](https://figshare.com/s/8a60e7017cd82db9a1b7), create a data folder `CoSpred/data`, and store the two zip files there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Configure Environment\n",
    "\n",
    "**Option 1: Pull the pre-built Docker image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: failed to resolve reference \"docker.io/xuel12pfizer/cospred:v0.3\": failed to do request: Head \"https://registry-1.docker.io/v2/xuel12pfizer/cospred/manifests/v0.3\": net/http: TLS handshake timeout\n"
     ]
    }
   ],
   "source": [
    "!docker pull xuel12pfizer/cospred:v0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Build the computational environment locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build . --tag cospred_docker -f conf/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3: Create a virtual environment and install packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env create -n cospred_cuda12_gpu_py39 -f conf/requirements_cospred_cuda12_gpu_py39.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reproduce the Workflow and Results in Batch Mode\n",
    "\n",
    "#### 3.1 Use Case I: Batch Mode for Training Using Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --platform linux/amd64 --rm --gpus all \\\n",
    "  --volume \"$PWD/data\":/data \\\n",
    "  --volume \"$PWD/results\":/results \\\n",
    "  cospred_docker bash \"scripts/run_training.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Use Case II: Batch Mode for Prediction Using Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'cospred_docker:latest' locally\n",
      "docker: Error response from daemon: pull access denied for cospred_docker, repository does not exist or may require 'docker login'\n",
      "\n",
      "Run 'docker run --help' for more information\n"
     ]
    }
   ],
   "source": [
    "!docker run --platform linux/amd64 --rm --gpus all \\\n",
    "  --volume \"$PWD/data\":/data \\\n",
    "  --volume \"$PWD/results\":/results \\\n",
    "  cospred_docker bash \"scripts/run_prediction.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699e785",
   "metadata": {},
   "source": [
    "* When finished, the final results will be stored in `results` folder.\n",
    "\n",
    "## Reproducing the workflow and results in interactive mode\n",
    "\n",
    "For advanced usage, the following are the step-by-step guides for fine-grain control modular execution of CoSpred.\n",
    "\n",
    "* OPTION 1: Docker with interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --platform linux/amd64 --rm -it --gpus all \\\n",
    "  --volume \"$PWD/data\":/data \\\n",
    "  --volume \"$PWD/results\":/results \\\n",
    "  --shm-size=32g \\\n",
    "  cospred_docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592eb892",
   "metadata": {},
   "source": [
    "* OPTION 2: Viturtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72da429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate cospred_cuda12_gpu_py39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1302e",
   "metadata": {},
   "source": [
    "Once done the environment setup, navigate to `CoSpred` working directory, move forward to following steps.\n",
    "\n",
    "### 1. Configuration\n",
    "\n",
    "* Main configuration regarding file location and preprocessing parameters could be found and modified in `params` folder. \n",
    "* For all the following modules, log files could be found under `prediction` folder.\n",
    "* For BiGRU based training parameters and model setup could be found in JSON files under `model_spectra` folder. Edit `model_construct.py` to modify architecture and generate compatible `model.json` file. Two examples `model_byion.json` and `model_fullspectrum.json` were provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python model_construct.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1629c",
   "metadata": {},
   "source": [
    "* For transformer based model setup, users could directly modify `cospred_model/model/transformerEncoder.py`, as well `train_transformer` module in `training_cospred.py`. \n",
    "\n",
    "### 2. Data Preprocessing\n",
    "\n",
    "#### Database search and pair identification with spectra\n",
    "\n",
    "* Create PSM file with identified peptides from softwares like Proteome Discoverer corresponding to each rawfiles from the experiment.\n",
    "\n",
    "#### Spectrum file format conversion\n",
    "\n",
    "* Convert rawfiles into mzml and mgf\n",
    "\n",
    "Msconvert can be run using GUI version of the software on windows computer or can use Docker on linux machine. We recommend to run MSCovert in Windows GUI. At the end, assuming files were generated, `*.mzML` and `*.mgf`. Keep these two type of files in folder `data/example/mzml` and `data/example/mgf` respectively, together with `example_PSMs.txt` and `example_InputFiles.txt` got from Proteome Discoverer in the folder `data/example`. Note that all file and folders names could be defined in the `params/constants_location.py`.\n",
    "\n",
    "* OPTION 1: The MGF file doesn't contain sequence information\n",
    "    * Split the dataset into train and test set. (About 15mins for 300k spectra)\n",
    "\n",
    "    20% spectra will be randomly selected for test by default, which could be modified in the script. `example_train.mgf` and `example_test.mgf` will be generated from this step. `rawfile2hdf_byion.py` (preparing dataset with b/y ion annotation) and `rawfile2hdf_cospred.py` (preparing dataset for full spectrum representation) are the scripts for this purpose. (2019 Macbook Pro, about 2 minitues for the example dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ede0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python rawfile2hdf_cospred.py -w split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbed03",
   "metadata": {},
   "source": [
    "* OPTION 1.1: Pair database search result with MGF spectrum, annotate B and Y ion for MSMS spectrum\n",
    "\n",
    "    Pyteomics is used to parse annotations of y and b ions and their fragments charges from MZML and MGF, and report to annotated MGF files for downstream spectrum prediction/viewing application. Note that to parse the input file correctly, you will likely need to adjust regex routine (in the `reformatMGF` function within `io_cospred.py`) according to the specific MGF format you are using. (2019 Macbook Pro, about 1 hour for the example dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6634217",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python rawfile2hdf_byion.py -w train\n",
    "!python rawfile2hdf_byion.py -w test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ebf16",
   "metadata": {},
   "source": [
    "* OPTION 1.2: Pair database search result with MGF spectrum, reformat to full MSMS using bins. (2019 Macbook Pro, about 2 minitues for the example dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef68359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python rawfile2hdf_cospred.py -w train\n",
    "!python rawfile2hdf_cospred.py -w test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fdb9eb",
   "metadata": {},
   "source": [
    "* OPTION 2: For MGF file with assigned peptide sequence (e.g. `example.mgf`), reformat to full MSMS using bins. Note: you may need to reformat MGF so that peptide sequence representation is compatible for downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeec107",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mgf2hdf_cospred.py -w reformat       # Reformat the MGF for CoSpred workflow.\n",
    "!python mgf2hdf_cospred.py -w split_usi      # Split the dataset into train and test set.\n",
    "!python mgf2hdf_cospred.py -w train          # Convert training set into full spectrum bins\n",
    "!python mgf2hdf_cospred.py -w test           # Convert testing set into full spectrum bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38135b9",
   "metadata": {},
   "source": [
    "At the end, a few files will be generated. `train.hdf5` and `test.hdf5` are input files for the following ML modules.\n",
    "\n",
    "### 3. In-house training procedure\n",
    "\n",
    "`training_cospred.py` is the script for customized training. Workflows could be selected by arguments, including 1) `-t`: fine-tuning / continue training the existing model; 2) `-f`: opt in full MS/MS spectrum model instead of B/Y ions; 3) `-c`: chunking the input dataset (to prevent memory overflow by large dataset); 4) `-b`: opt in for BiGRU model instead of Transformer.\n",
    "\n",
    "#### Representative training workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python training_cospred.py      # Training B/Y ion spectrum prediction using Transformer architecture.\n",
    "# !python training_cospred.py -b   # Training B/Y ion spectrum prediction using BiGRU architecture.\n",
    "# !python training_cospred.py -bf   # Training full spectrum prediction using BiGRU architecture. \n",
    "# !python training_cospred.py -f   # Training full spectrum prediction using Transformer architecture. \n",
    "# !python training_cospred.py -bft   # Fine-tuning full spectrum prediction using BiGRU architecture with pre-trained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cfbe5",
   "metadata": {},
   "source": [
    "During the training procedure under each epoch, model weights files will be auto-generated under the folder `model_spectra`. Naming of files will be like below,\n",
    "* For B/Y ion, BiGRU model: `prosit_byion_[YYYYMMDD]_[HHMMSS]_epoch[integer]_loss[numeric].hdf5`\n",
    "* For full spectrum, BiGRU model: `prosit_full_[YYYYMMDD]_[HHMMSS]_epoch[integer]_loss[numeric].hdf5`\n",
    "* For B/Y ion, Transformer model: `transformer_byion_[YYYYMMDD]_[HHMMSS]_epoch[integer]_loss[numeric].pt`\n",
    "* For full spectrum, Transformer model: `transformer_full_[YYYYMMDD]_[HHMMSS]_epoch[integer]_loss[numeric].pt`\n",
    "\n",
    "#### Note: Usage for novel modification\n",
    "\n",
    "To fine-tune the foundation model or re-train the model, following scripts and parameters needs to be modified. In this demo, we will use a non unimod chemical modification \"Desthiobiotin\" for example.\n",
    "\n",
    "* Ensure that the related information of (DTBIA) is properly added in your `constants.py` file, as following.\n",
    "```python\n",
    "# add to alphabet\n",
    "ALPHABET = {\n",
    "    \"C(DTBIA)\": 26,  # Alphabet\n",
    "}\n",
    "# define the mass\n",
    "MODIFICATION = {\n",
    "    'DTBIA': 296.185,\n",
    "}\n",
    "# add to amino acid\n",
    "AMINO_ACID[\"C(DTBIA)\"] = AMINO_ACID[\"C\"] + MODIFICATION[\"DTBIA\"]\n",
    "# define the chemical composition\n",
    "MODIFICATION_COMPOSITION = {\n",
    "    'C(DTBIA)': {'H': 24, 'C': 14, 'O': 3, 'N': 4},     # Chemical composition\n",
    "}\n",
    "# annotate the novel modification with proforma, so that pyteomics library can parse\n",
    "VARMOD_PROFORMA = {\n",
    "    'C(DTBIA)': 'C[+296.185]',\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb2431",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Inference\n",
    "\n",
    "Keep the best model under `model_spectra` folder as the trained model for inference phase. Some pre-trained model can be downloaded from [FigShare](https://figshare.com/s/8a60e7017cd82db9a1b7). \n",
    "\n",
    "#### 4.1 Spectrum library generation\n",
    "\n",
    "With trained models, predict spectrum given peptide sequences from `peptidelist_test.csv`. All inference results including metrics, plots, and spectra library will be stored under `prediction` folder. Predicted spectra will be stored in `speclib_prediction.msp`.\n",
    "\n",
    "Workflows could be selected by arguments, including 1) `-f`: opt in full MS/MS spectrum model instead of B/Y ions; 2) `-c`: chucking the input dataset (to prevent memory overflow by large dataset); 3) `-b`: opt in for BiGRU model instead of Transformer. Some examples like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-19 06:09:41.957014: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-19 06:09:52,443 - INFO - Pediction result directory created: ./prediction/\n",
      "Loading weight from: ./model_spectra/transformer_byion_20250511_205306_epoch014_loss0.05858.pt\n",
      "2025-05-19 06:09:52,723 - INFO - Transformer model was loaded successfully.\n",
      "2025-05-19 06:09:52,723 - INFO - [USER] Loaded weight from: ./model_spectra/transformer_byion_20250511_205306_epoch014_loss0.05858.pt\n",
      "2025-05-19 06:09:52,723 - INFO - [STATUS] MODEL LOADING finished.\n",
      "2025-05-19 06:09:52,723 - INFO - [STATUS] PREDICTION MODE: Generating prediction list without reference.\n",
      "2025-05-19 06:09:52,724 - INFO - Reference CSV ./data/example/peptidelist_test.csv was provided. Move on to prediction.\n",
      "2025-05-19 06:09:52,795 - INFO - [STATUS] INPUT PREPARATION finished. Start PREDICTION...\n",
      "2025-05-19 06:09:52,803 - INFO - Prediction list without evaluation\n",
      "2025-05-19 06:09:53,585 - INFO - Model device: cpu\n",
      "2025-05-19 06:09:53,585 - INFO - x_batch device: cpu\n",
      "2025-05-19 06:09:53,585 - INFO - Processing batch 1/1, batch size: 999\n",
      "2025-05-19 06:09:59,416 - INFO - Found 1 batch files to concatenate.\n",
      "2025-05-19 06:09:59,419 - INFO - Predictions Dimension: (999, 174)\n",
      "2025-05-19 06:09:59,815 - INFO - [STATUS] Whole CoSpred Workflow ... COMPLETE!\n",
      "2025-05-19 06:09:59,815 - INFO - [STATUS] Elapsed time: 7.371530055999756 seconds\n"
     ]
    }
   ],
   "source": [
    "!python prediction.py      # Predict B/Y ion spectrum prediction using Transformer architecture.\n",
    "# !python prediction.py -b   # Predict B/Y ion spectrum prediction using BiGRU architecture.\n",
    "# !python prediction.py -bf  # Predict full spectrum prediction using BiGRU architecture.\n",
    "# !python prediction.py -f   # Predict full spectrum prediction using Transformer architecture.\n",
    "# !python prediction.py -fc  # Predict full spectrum prediction using Transformer architecture, with chunking for large peptide lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Spectrum library prediction with reference for evaluation\n",
    "\n",
    "Optionally, performance evaluation could be executed with `-e` argument, as long as ground truth a) `test.hdf5` or b) `example_PSMs.txt` with `test_usi.mgf` are provided, so that reference spectrum for the peptides could be extracted from database search result and the raw mass-spec data. Examples as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prediction.py -e    # Predict B/Y ion spectrum prediction using Transformer architecture.\n",
    "# !python prediction.py -be   # Predict B/Y ion spectrum prediction using BiGRU architecture.\n",
    "# !python prediction.py -bfe  # Predict full spectrum prediction using BiGRU architecture.\n",
    "# !python prediction.py -fe   # Predict full spectrum prediction using Transformer architecture.\n",
    "# !python prediction.py -fce  # Predict full spectrum prediction using Transformer architecture, with chunking for large peptide lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of prediction will be generated under `prediction`, including predicted spectra library `speclib_prediction.msp` and `speclib_prediction.mgf`, plots and metrics under `prediction_library`, some other intermediate files for recording or diagnosis purpose.\n",
    "\n",
    "### 5. Plotting\n",
    "Predicted spectrum and mirror plot for visual evaluation could be separately generated by `spectra_plot.py`. By default, the required inputs are `peptidelist_predict.csv` (peptides list), `test_reformatted.mgf` (reference spectra), and `speclib_prediction.mgf` (predicited spectra). File names and location could be defined by `params/constants`. Plots will be stored in `prediction/plot` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python spectra_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09822ea0",
   "metadata": {},
   "source": [
    "# CoSpred: Machine Learning Workflow to Predict Tandem Mass Spectrum in Proteomics\n",
    "\n",
    "**Authors:**\n",
    "- Liang Xue<sup>1*</sup>, Shivani Tiwary<sup>2</sup>, Mykola Bordyuh<sup>1</sup>, Robert Stanton<sup>1*</sup>\n",
    "\n",
    "**Affiliations:**\n",
    "1. Machine Learning and Computational Sciences, Pfizer Worldwide R&D, Cambridge, MA, USA\n",
    "2. Machine Learning and Computational Sciences, Pfizer Worldwide R&D, Berlin, Germany\n",
    "\n",
    "**Correspondence:**\n",
    "- Email: [liang.xue@pfizer.com](mailto:liang.xue@pfizer.com) or [robert.stanton@pfizer.com](mailto:robert.stanton@pfizer.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cospred_cpu_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
